{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "575db842",
   "metadata": {},
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d3b91b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kallo\\AppData\\Local\\Temp\\ipykernel_24096\\1770363567.py:14: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from time import time\n",
    "import pybullet as p\n",
    "import copy\n",
    "\n",
    "from Environments.environment_sim2 import Environment\n",
    "from Config.constants import (WORKSPACE_LIMITS)\n",
    "from V1_destination_prediction.Test_cases.tc3_no_bottom import TestCase1\n",
    "\n",
    "#Importing Python Libraries\n",
    "import glob\n",
    "import imp\n",
    "import math\n",
    "import gc\n",
    "from sre_constants import SUCCESS\n",
    "import datetime\n",
    "import pybullet as p\n",
    "import cv2\n",
    "import numpy as np\n",
    "from graphviz import Digraph\n",
    "import argparse\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "import copy\n",
    "import json\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "\n",
    "#Importing Torch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from Environments.environment_sim2 import Environment\n",
    "import Environments.utils as env_utils\n",
    "from Environments.utils import sample_goal, get_pose_distance\n",
    "\n",
    "# --------------------- Imports from V1_destination_prediction: -------------------------- #\n",
    "\n",
    "from V1_destination_prediction.Test_cases.tc3_no_bottom_sim import TestCase1\n",
    "#from V1_destination_prediction.Test_cases.tc3_no_bottom import TestCase1\n",
    "\n",
    "# ---------------------------------------------------------------------------------------- #\n",
    "\n",
    "#Imports from V2_next_best_action:\n",
    "from V2_next_best_action.models.dqn_v2 import pushDQN2\n",
    "\n",
    "#Imports from create_env.py:\n",
    "from create_env import get_push_start, get_max_extent_of_target_from_bottom, get_push_start_POSMAX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c1fa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU Available?  True\n"
     ]
    }
   ],
   "source": [
    "#Initializing a pyTorch device, on which torch tensors will be allocated\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Is GPU Available? \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cdc9db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Model Definition: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pushDQN2(\n",
       "  (layer1): Linear(in_features=6, out_features=128, bias=True)\n",
       "  (layer2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (layer3): Linear(in_features=128, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ITER = 0   \n",
    "\n",
    "#Define the state space:\n",
    "n_observations = 6 # 3 for initial state, 3 for goal state\n",
    "\n",
    "#Define the action space:\n",
    "n_actions = 16 # 16 push + 1 grasp ???How are the 16 push actions distributed, I mean how are they applied and where?\n",
    "\n",
    "#Initialize the DQN policy (states --> action values) neural network, set it to use cuda, and assign the cuda device to be used.\n",
    "policy_net = pushDQN2(n_observations, n_actions, use_cuda=True).to(device)\n",
    "\n",
    "#???Note: Do not confuse the \"policy_net\" for being the policy, its actually the Q-function I guess, it gives us the value of\n",
    "#each state-action pair.\n",
    "\n",
    "\"\"\"PYTORCH MODEL LOADING PROCESS:\"\"\"\n",
    "\n",
    "#load a previous checkpoint .pt file\n",
    "checkpoint = torch.load('V2_next_best_action/models/model_checkpoints/dqnv2/model7/5350.pt')\n",
    "#Assign the parameters from the checkpoint to the policy network\n",
    "policy_net.load_state_dict(checkpoint)\n",
    "\n",
    "print(\"Policy Model Definition: \")\n",
    "#Evaluate and print model\n",
    "policy_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "376fbebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    '''Select the next best action \n",
    "    state: tensor(shape=(6))\n",
    "    '''\n",
    "    with torch.no_grad():  #Make sure that gradients are not calculated for parameters, because they aren't needed here\n",
    "        \n",
    "        #Pass the state through the state-action value network, then find the maximum value, and index into the 1st element to\n",
    "        #get the action index of the maximum value. Then reshape the tensor to (1,1).\n",
    "        return policy_net(state).max(1)[1].view(1, 1)\n",
    "\n",
    "    \n",
    "def get_reward2(prev_state, current_state):\n",
    "    '''\n",
    "    prev_state: (x1, y1, theta1, x2, y2, theta2)\n",
    "    current_state: (x3, y3, theta3, _, _, _)\n",
    "    '''\n",
    "\n",
    "    #???\n",
    "    \n",
    "    #Difference between norms of previous state's error in between goal coordinates and initial coordinates, and the same error \n",
    "    #for current state\n",
    "    pos_diff = np.linalg.norm(prev_state[0:2] - prev_state[3:5]) - np.linalg.norm(current_state[0:2] - prev_state[3:5])\n",
    "    \n",
    "    #Difference between norms of previous state's initial theta and goal theta, and the same error for current state:\n",
    "    orn_diff = np.linalg.norm(prev_state[2:3] - prev_state[5:6]) - np.linalg.norm(current_state[2:3] - prev_state[5:6])\n",
    "    \n",
    "    #Reward is the weighted sum of difference in position and difference in orientation, with weights = 1, 0.1\n",
    "    reward = pos_diff + 0.1*orn_diff  \n",
    "    \n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ac7a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_joint_cost(all_joints):\n",
    "    '''\n",
    "    all_joints = np.array(n, 6)\n",
    "    '''\n",
    "    print(len(all_joints), len(all_joints[0]))\n",
    "    cost = 0\n",
    "    for i in range(1, len(all_joints)-1):\n",
    "        temp_cost = 0\n",
    "        for j in range(6):\n",
    "            temp_cost += ((all_joints[i][j] - all_joints[i-1][j]))**2\n",
    "        cost += np.sqrt(temp_cost)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bc26e0",
   "metadata": {},
   "source": [
    "### Get best trajectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d6a4b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.35       -0.15      ]\n",
      " [ 0.39985316 -0.19574957]\n",
      " [ 0.52857485 -0.28002247]\n",
      " [ 0.68985863 -0.32289595]\n",
      " [ 0.77719896 -0.24261104]\n",
      " [ 0.72106202 -0.018988  ]\n",
      " [ 0.66        0.12      ]]\n"
     ]
    }
   ],
   "source": [
    "min_cost = 1e+500\n",
    "\n",
    "save_folder = \"Run1\"\n",
    "\n",
    "for _, _, file_names in os.walk(\"Saves/\" + save_folder):\n",
    "    for file_name in file_names:\n",
    "        if re.search('costs', file_name):\n",
    "            cost = np.load(\"Saves/\" + save_folder + \"/\" + file_name)\n",
    "            for i in range(cost.size):\n",
    "                if cost[i]< min_cost:\n",
    "                    min_cost = cost[i]\n",
    "                    index = i\n",
    "                    time_stamp = re.findall('s.*n', file_name)[0][3:-1]\n",
    "\n",
    "best_cost = np.load(\"Saves/\" + save_folder + \"/costs\" + time_stamp + 'npy')[index]\n",
    "best_traj = np.load(\"Saves/\" + save_folder + \"/latest_trajectory_list\" + time_stamp + 'npy')[index]\n",
    "print(best_traj)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a80c28",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m min_cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e+500\u001b[39m\n\u001b[0;32m      3\u001b[0m save_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun17_3cylinders\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, file_names \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mwalk(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m save_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/costs_and_trajectories/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m file_names:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosts\u001b[39m\u001b[38;5;124m'\u001b[39m, file_name):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "min_cost = 1e+500\n",
    "\n",
    "save_folder = \"Run17_3cylinders\"\n",
    "\n",
    "for _, _, file_names in os.walk(\"Results/\" + save_folder + \"/costs_and_trajectories/\"):\n",
    "    for file_name in file_names:\n",
    "        if re.search('costs', file_name):\n",
    "            cost = np.load(\"Results/\" + save_folder + \"/costs_and_trajectories/\" + file_name)\n",
    "            for i in range(cost.size):\n",
    "                if cost[i]< min_cost:\n",
    "                    min_cost = cost[i]\n",
    "                    index = i\n",
    "                    time_stamp = re.findall('s.*n', file_name)[0][3:-1]\n",
    "\n",
    "best_cost = np.load(\"Results/\" + save_folder + \"/costs_and_trajectories\" + \"/costs\" + time_stamp + 'npy')[index]\n",
    "best_traj = np.load(\"Results/\" + save_folder + \"/costs_and_trajectories\" +  \"/latest_trajectory_list\" + time_stamp + 'npy')[index]\n",
    "print(best_traj)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1103ab1",
   "metadata": {},
   "source": [
    "### Simulate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98d258c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_policy(env, cur_traj, START_PT, threshold_d, WORKSPACE_LIMITS, MAX_PUSH_ITER=30, obstacle_num = 1):\n",
    "    '''\n",
    "    '''\n",
    "    #Angular directions along which the object can be pushed (16 standard directions), divided equally from 360 degrees (2pi)\n",
    "    push_directions = [0, np.pi/8, np.pi/4, 3*np.pi/8,\n",
    "                    np.pi/2, 5*np.pi/8, 3*np.pi/4, 7*np.pi/8, \n",
    "                    np.pi, 9*np.pi/8, 5*np.pi/4, 11*np.pi/8,  \n",
    "                    3*np.pi/2, 13*np.pi/8, 7*np.pi/4, 15*np.pi/8] # 16 standard directions\n",
    "    \n",
    "    #Reset the environment:\n",
    "    #This resets objects, sets gravity, resets simulation timer, loads the plane, loads workspace table, sets the Physical\n",
    "    #Dynamics like friction, damping etc., loads in the URDF and stores it joint ids in the environment\n",
    "    env.reset()\n",
    "    \n",
    "    #Create a Test Case:\n",
    "    testcase1 = TestCase1(env)\n",
    "    \n",
    "    #Sets up the task on the workspace, with a target object and a bottom object to be picked up by the robot. \n",
    "    #body_ids has the object ID of the target object, and sucess is true if the target is within bounds of the \n",
    "    \n",
    "    # ----------------------------------------------------------- #\n",
    "    \n",
    "    body_ids, sucess = testcase1.create_specific_test_case(targetPos=START_PT, obstacle_config = \"Results/\" + save_folder + \"/obstacle_config.npy\")\n",
    "    #body_ids, sucess = testcase1.create_specific_test_case(targetPos=START_PT, scene_id = 0)\n",
    "    \n",
    "    # ----------------------------------------------------------- #\n",
    "    \n",
    "    #body_ids[0] is the target object handle, \n",
    "    targetPos, targetOrn = p.getBasePositionAndOrientation(body_ids[0])\n",
    "    \n",
    "    #Initialize empty lists for marker poses and marker yaws:\n",
    "    marker_poses = []\n",
    "    marker_yaws = []\n",
    "    \n",
    "    INVALID_POS = False\n",
    "    \n",
    "    for k in range(len(cur_traj)-1):\n",
    "        \n",
    "        #copy the position of target object to position of marker\n",
    "        marker_pos = copy.deepcopy(np.array(targetPos))\n",
    "        \n",
    "        #Assign the (x,y) of the marker position to the (x,y) of the (k+1)th point of the trajectory\n",
    "        #Remember that (k+1) goes from 1 to TRAJ_LEN, that is, from the second point to last point of trajectory.\n",
    "        marker_pos[0] = cur_traj[k+1][0]                      \n",
    "        marker_pos[1] = cur_traj[k+1][1]\n",
    "        \n",
    "        #Append the marker position to the list of marker positions\n",
    "        marker_poses.append(marker_pos)\n",
    "        \n",
    "        #Sample the yaw angle of the marker position from a uniform distribution and append it to the list of marker yaw angles\n",
    "        marker_yaw = np.random.uniform(low=0, high=np.pi)\n",
    "        marker_yaws.append(marker_yaw)\n",
    "\n",
    "    ###################################################################################################\n",
    "    #??? This section should not even run since INVALID_POS will always be False.\n",
    "    if INVALID_POS == True:\n",
    "        cost = OUT_OF_BOUNDS_COST\n",
    "        # sample_costs.append(cost)\n",
    "        all_joints = []\n",
    "        # sample_joint_trajectories.append(all_joints)\n",
    "        print(f\"{ITER}. Cost: {cost} -------------------------\")  \n",
    "        return cost, all_joints\n",
    "    ##################################################################################################\n",
    "    \n",
    "    #Loop through trajectory points:\n",
    "    \n",
    "    success = 0\n",
    "    collisions = 0\n",
    "    oob = 0\n",
    "    time_taken = time()\n",
    "    all_joints = []\n",
    "    \n",
    "    for k in range(len(cur_traj) - 1):\n",
    "        \n",
    "        dist_pos = 100 #??? This is getting reassigned later anyways\n",
    "        \n",
    "        marker_pos = marker_poses[k] # Get the kth point in the trajectory\n",
    "\n",
    "        #Get the position and orientation of the target object, \n",
    "        #and find the distance between the target object and the kth marker\n",
    "        targetPos, targetOrn = p.getBasePositionAndOrientation(body_ids[0]) \n",
    "        dist_pos = np.linalg.norm(marker_pos[0:2] - np.array(targetPos)[0:2])\n",
    "        \n",
    "        marker_orn = p.getQuaternionFromEuler([0, 0, marker_yaw]) #Convert marker yaw to Quaternion representation\n",
    "        \n",
    "        #Add a marker object to the environment, and get its object ID\n",
    "        marker_obj, goal_suc = testcase1.add_marker_obj(marker_pos, marker_orn, half_extents=testcase1.current_target_size/2)\n",
    "        \n",
    "        #Append the ID of the marker object to the body IDs.\n",
    "        body_ids.append(marker_obj)\n",
    "        \n",
    "        PUSH_ITER = 0\n",
    "        \n",
    "        obstacle_initial_poses = np.zeros((obstacle_num, 7))\n",
    "\n",
    "        for j in range(obstacle_num):\n",
    "            ob_start_pos, ob_start_orn = p.getBasePositionAndOrientation(body_ids[-1*(j+1)])\n",
    "            obstacle_initial_poses[j, :3] = ob_start_pos[:]\n",
    "            obstacle_initial_poses[j, 3:] = ob_start_orn[:]\n",
    "        \n",
    "        #Loop until the distance to current marker is less than threshold, and the number of pushes exceeds max no. of pushes\n",
    "        while dist_pos > threshold_d and PUSH_ITER < MAX_PUSH_ITER:\n",
    "            \n",
    "            print(f\"\\rWaypoint: {k}\\tPush: {PUSH_ITER}\", end=\"\")\n",
    "            \n",
    "            #Get the position and orientation of the target object again???\n",
    "            targetPos, targetOrn = p.getBasePositionAndOrientation(body_ids[0])\n",
    "            target_euler = p.getEulerFromQuaternion(targetOrn)  #Get the orientation in euler angles of the target\n",
    "            \n",
    "            #Get the yaw angle of the kth marker\n",
    "            marker_yaw = marker_yaws[k]\n",
    "\n",
    "            #GATHER THE CURRENT STATE (FOR MOVING TARGET OBJECT TO THE MARKER):\n",
    "            # 1) Get the (x,y,theta) position and orientation of the target object: \n",
    "            cur_target_st = np.array([targetPos[0], targetPos[1], target_euler[2]], dtype=np.float64)\n",
    "            # 2) Get the (x,y,theta) position and orientation of the marker object: \n",
    "            cur_target_goal = np.array([marker_pos[0], marker_pos[1], marker_yaw], dtype=np.float64)\n",
    "            # 3) Stack these both to get the 6-vector state:\n",
    "            cur_state = np.hstack((cur_target_st, cur_target_goal))\n",
    "            \n",
    "            #Convert state to a tensor and add an extra dimension on it, then store in dictionary:\n",
    "            state = {\n",
    "                'cur_state': torch.tensor(cur_state, dtype=torch.float, device=device).unsqueeze(0),\n",
    "            }\n",
    "            \n",
    "            #Select the action with the highest value??? the output is a (1,1) action index\n",
    "            action = select_action(state['cur_state'])\n",
    "            \n",
    "            #Check if the value inside the action tensor is in 0-15:\n",
    "            if action.item() in range(0, 16):\n",
    "                \n",
    "                bottomPos, bottomOrn = [], []   #Initialize empty lists for bottom object's position and orientation\n",
    "                \n",
    "                #Get the target object's position and orientation again???\n",
    "                targetPos, targetOrn = p.getBasePositionAndOrientation(body_ids[0])\n",
    "                \n",
    "                #Extract the size of the target object (l, b, h) from the test case\n",
    "                current_target_obj_size = testcase1.current_target_size\n",
    "                \n",
    "                #Get the angle of direction of the push using the action chosen (Why are we doing modulus???)\n",
    "                push_dir = push_directions[(action.item())%16]\n",
    "                \n",
    "                #Get the (x,y,z) starting coordinate and ending coordinate for the push by the manipulator.\n",
    "                push_start, push_end = get_push_start_POSMAX(push_dir, bottomPos, bottomOrn,\n",
    "                                                targetPos, targetOrn, current_target_obj_size, is_viz=False)\n",
    "                \n",
    "                \n",
    "                succ, cur_joints = env.push(push_start, push_end)\n",
    "                all_joints.extend(cur_joints)\n",
    "                \n",
    "                if not succ:\n",
    "                    oob += 1\n",
    "\n",
    "                new_target_pos, new_target_orn = p.getBasePositionAndOrientation(body_ids[0])\n",
    "                target_euler = p.getEulerFromQuaternion(new_target_orn)\n",
    "\n",
    "                new_target_st = np.array([new_target_pos[0], new_target_pos[1], target_euler[2]], dtype=np.float32)\n",
    "                new_state = np.hstack((new_target_st, cur_target_goal))\n",
    "                next_state = {\n",
    "                    'cur_state': torch.tensor(new_state, dtype=torch.float, device=device).unsqueeze(0)\n",
    "                }\n",
    "                state=next_state\n",
    "                reward = get_reward2(current_state=new_state, prev_state=state['cur_state'].squeeze().cpu().numpy())\n",
    "                dist_pos = np.linalg.norm(cur_target_goal[0:2] - new_target_st[0:2])\n",
    "                \n",
    "            # ------------ Collision Cost -------------- #\n",
    "\n",
    "            obstacle_final_poses = np.zeros((obstacle_num, 7))\n",
    "\n",
    "            for j in range(obstacle_num):\n",
    "                ob_end_pos, ob_end_orn = p.getBasePositionAndOrientation(body_ids[-1*(j+1)])\n",
    "                obstacle_final_poses[j, :3] = ob_end_pos[:]\n",
    "                obstacle_final_poses[j, 3:] = ob_end_orn[:]\n",
    "\n",
    "            pose_diff = obstacle_final_poses - obstacle_initial_poses\n",
    "            print(\" Pose difference = \", np.linalg.norm(pose_diff))\n",
    "            \n",
    "            if np.linalg.norm(pose_diff) > 0.005:\n",
    "                collisions += 1\n",
    "            \n",
    "            #collision_cost += 100000 * np.linalg.norm(pose_diff)\n",
    "\n",
    "            # -------------------------------------------- #\n",
    "\n",
    "            PUSH_ITER += 1\n",
    "        \n",
    "        if INVALID_POS==True:\n",
    "            break\n",
    "            \n",
    "    # ------------ METRICS ---------------------- #\n",
    "    \n",
    "    error_threshold = 0.01\n",
    "    targetPos, targetOrn = p.getBasePositionAndOrientation(body_ids[0])\n",
    "    error = np.linalg.norm(targetPos[:2] - cur_traj[-1, :2])\n",
    "    \n",
    "    time_taken = time() - time_taken\n",
    "    \n",
    "    joint_cost = get_joint_cost(all_joints)\n",
    "    \n",
    "    st_time = time()\n",
    "    \n",
    "    # sample_costs.append(cost)\n",
    "    # sample_joint_trajectories.append(np.array(all_joints))\n",
    "    print(f\"{ITER}. Cost: {joint_cost} -------------------------\")\n",
    "    # print(f\"Time to get the joint cost: {time()-st_time}\")\n",
    "    return error, collisions, oob, time_taken, joint_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35835a34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obstacle Locations:  [[ 0.45 -0.05]\n",
      " [ 0.65 -0.1 ]\n",
      " [ 0.35  0.2 ]]\n",
      "Waypoint: 0\tPush: 0 Pose difference =  0.0009683087361251571\n",
      "Waypoint: 0\tPush: 1 Pose difference =  0.0019615055462643164\n",
      "Waypoint: 0\tPush: 2 Pose difference =  0.0027864509825677943\n",
      "Waypoint: 0\tPush: 3 Pose difference =  0.0037696684224284133\n",
      "Waypoint: 0\tPush: 4 Pose difference =  0.004585817283072956\n",
      "Waypoint: 0\tPush: 5 Pose difference =  0.0055505667455890435\n",
      "Waypoint: 0\tPush: 6 Pose difference =  0.006359082955125694\n",
      "Waypoint: 0\tPush: 7 Pose difference =  0.007310515939216328\n",
      "Waypoint: 0\tPush: 8 Pose difference =  0.008272130610851957\n",
      "Waypoint: 0\tPush: 9 Pose difference =  0.009195434691206598\n",
      "Waypoint: 0\tPush: 10 Pose difference =  0.010023174355019553\n",
      "Waypoint: 0\tPush: 11 Pose difference =  0.010918016509544787\n",
      "Waypoint: 0\tPush: 12 Pose difference =  0.011790893591803074\n",
      "Waypoint: 0\tPush: 13 Pose difference =  0.011864176280976033\n",
      "Waypoint: 0\tPush: 14 Pose difference =  0.011499347596927457\n",
      "Waypoint: 0\tPush: 15 Pose difference =  0.011448761577343041\n",
      "Waypoint: 0\tPush: 16 Pose difference =  0.011591858362741765\n",
      "Waypoint: 0\tPush: 17 Pose difference =  0.012346443307628602\n",
      "Waypoint: 0\tPush: 18 Pose difference =  0.013049597817773272\n",
      "Waypoint: 0\tPush: 19 Pose difference =  0.013784339673147699\n",
      "33246 6\n",
      "0. Cost: 119.308888813132 -------------------------\n"
     ]
    }
   ],
   "source": [
    "#CURRENT SCENE_ID FOR SIMULATION IS 5\n",
    "\n",
    "env = Environment(gui=True)\n",
    "env.reset()\n",
    "threshold_d = 0.025\n",
    "\n",
    "success, collisions, oob, time_taken, joint_cost = run_policy(env = env, \n",
    "                                                              cur_traj = best_traj[1:].copy(), \n",
    "                                                              START_PT = best_traj[0].copy(), \n",
    "                                                              threshold_d = threshold_d, \n",
    "                                                              WORKSPACE_LIMITS = WORKSPACE_LIMITS, \n",
    "                                                              MAX_PUSH_ITER=20,\n",
    "                                                              obstacle_num = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "747c6322",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor Best Trajectory in \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43msave_folder\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m : \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError between final point and goal point of trajectory = \u001b[39m\u001b[38;5;124m\"\u001b[39m, success)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of times object goes out of bounds = \u001b[39m\u001b[38;5;124m\"\u001b[39m, oob)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'save_folder' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"For Best Trajectory in \" + save_folder, \" : \")\n",
    "print(\"Error between final point and goal point of trajectory = \", success)\n",
    "print(\"Number of times object goes out of bounds = \", oob)\n",
    "print(\"Time taken to complete trajectory = \", time_taken)\n",
    "print(\"Total Joint Cost = \", joint_cost)\n",
    "\n",
    "print(success, collisions, oob, time_taken, joint_cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RRC_RL_Grasping",
   "language": "python",
   "name": "rrc_rl_grasping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
